import cv2
import numpy as np
import threading
import time
from collections import Counter
from config import Config

print("üöÄ Inicializando sistema de detecci√≥n...")

# Modelo YOLO
model = None
if Config.USE_YOLO and Config.YOLO_MODEL_PATH:
    try:
        from ultralytics import YOLO
        model = YOLO(Config.YOLO_MODEL_PATH)
        print("‚úÖ YOLO cargado correctamente")
    except Exception as e:
        print(f"‚ùå Error cargando YOLO: {e}")
        model = None
else:
    print("‚ÑπÔ∏è  Modo simulaci√≥n activado (sin YOLO)")

class VideoProcessor:
    def __init__(self):
        self.video_caps = {}
        self.current_frames = {}
        self.vehicle_counts = {}
        self.vehicle_classes = {}
        self.processing = True
        
        print(f"üìπ Cargando {len(Config.VIDEO_PATHS)} videos...")
        self._load_videos()
        
        # Iniciar procesamiento
        self._start_processing()
    
    def _load_videos(self):
        """Carga todos los videos"""
        for cam_id, video_path in enumerate(Config.VIDEO_PATHS):
            try:
                cap = cv2.VideoCapture(video_path)
                if cap.isOpened():
                    self.video_caps[cam_id] = cap
                    self.vehicle_counts[cam_id] = 0
                    self.vehicle_classes[cam_id] = {}
                    print(f"‚úÖ Video {cam_id}: {video_path}")
                else:
                    print(f"‚ùå No se pudo abrir: {video_path}")
                    # Crear video simulado como fallback
                    self._create_simulated_video(cam_id)
            except Exception as e:
                print(f"‚ùå Error cargando video {video_path}: {e}")
                self._create_simulated_video(cam_id)
    
    def _create_simulated_video(self, cam_id):
        """Crea un video simulado cuando no hay video real"""
        print(f"üé¨ Creando video simulado para c√°mara {cam_id}")
        # En una implementaci√≥n real, aqu√≠ crear√≠as un video con OpenCV
        # Por ahora, simplemente inicializamos los contadores
        self.vehicle_counts[cam_id] = 0
        self.vehicle_classes[cam_id] = {}
    
    def _start_processing(self):
        """Inicia el procesamiento de todos los videos"""
        for cam_id in self.video_caps.keys():
            thread = threading.Thread(target=self._process_camera, args=(cam_id,), daemon=True)
            thread.start()
            print(f"üîÑ Iniciando procesamiento c√°mara {cam_id}")
    
    def _process_camera(self, cam_id):
        """Procesa una c√°mara espec√≠fica"""
        cap = self.video_caps.get(cam_id)
        if not cap:
            print(f"‚ùå No hay captura para c√°mara {cam_id}")
            return
        
        frame_count = 0
        while self.processing:
            try:
                ret, frame = cap.read()
                frame_count += 1
                
                if not ret:
                    # Reiniciar video
                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    continue
                
                # Procesar cada 10 frames para mejor performance
                if frame_count % 10 == 0:
                    vehicles, classes = self._detect_vehicles(frame, cam_id)
                    
                    # Actualizar contadores
                    self.vehicle_counts[cam_id] = vehicles
                    self.vehicle_classes[cam_id] = classes
                    self.current_frames[cam_id] = frame
                    
                    if vehicles > 0:
                        print(f"üéØ C√°mara {cam_id}: {vehicles} veh√≠culos - {classes}")
                
                time.sleep(0.01)  # Controlar FPS
                
            except Exception as e:
                print(f"‚ùå Error procesando c√°mara {cam_id}: {e}")
                time.sleep(1)
    
    def _detect_vehicles(self, frame, cam_id):
        """Detecta veh√≠culos en un frame"""
        if model:
            return self._detect_with_yolo(frame)
        else:
            return self._simulate_detection(cam_id)
    
    def _detect_with_yolo(self, frame):
        """Detecci√≥n usando YOLO"""
        try:
            # Reducir resoluci√≥n para mejor performance
            small_frame = cv2.resize(frame, (640, 480))
            
            # Ejecutar detecci√≥n
            results = model(small_frame, verbose=False, conf=0.4)
            
            vehicles = 0
            classes_dict = {}
            
            for result in results:
                if result.boxes is not None:
                    for box in result.boxes:
                        class_id = int(box.cls[0])
                        class_name = model.names[class_id]
                        
                        # Filtrar solo veh√≠culos
                        if class_name.lower() in ['carro', 'camion', 'bus', 'motitaxi', 'ambulancia']:
                            vehicles += 1
                            classes_dict[class_name] = classes_dict.get(class_name, 0) + 1
            
            return vehicles, classes_dict
            
        except Exception as e:
            print(f"‚ùå Error en detecci√≥n YOLO: {e}")
            return self._simulate_detection(0)  # Usar simulaci√≥n como fallback
    
    def _simulate_detection(self, cam_id):
        """Simulaci√≥n de detecci√≥n cuando YOLO no est√° disponible"""
        # Simular tr√°fico variable por c√°mara
        base_traffic = [3, 2, 4, 1]  # Tr√°fico base por c√°mara
        variation = np.random.randint(-2, 3)
        
        vehicles = max(0, base_traffic[cam_id % 4] + variation)
        classes_dict = {'car': vehicles}  # Simular que todos son autos
        
        return vehicles, classes_dict
    
    def get_frame(self, cam_id):
        """Obtiene frame para streaming"""
        frame = self.current_frames.get(cam_id)
        
        if frame is not None:
            # Anotar frame con informaci√≥n
            vehicles = self.vehicle_counts.get(cam_id, 0)
            frame = self._annotate_frame(frame, cam_id, vehicles)
        else:
            # Frame por defecto
            frame = self._create_default_frame(cam_id)
        
        # Codificar como JPEG
        ret, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
        return buffer.tobytes()
    
    def _annotate_frame(self, frame, cam_id, vehicles):
        """A√±ade informaci√≥n al frame"""
        # Redimensionar si es muy grande
        if frame.shape[0] > 480 or frame.shape[1] > 640:
            frame = cv2.resize(frame, (640, 480))
        
        # A√±adir overlay
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (300, 80), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
        
        # Texto informativo
        cv2.putText(frame, f"Camara {cam_id + 1}", (20, 35), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(frame, f"Vehiculos: {vehicles}", (20, 65), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return frame
    
    def _create_default_frame(self, cam_id):
        """Crea un frame por defecto"""
        frame = np.zeros((480, 640, 3), dtype=np.uint8)
        frame.fill(50)  # Fondo oscuro
        
        cv2.putText(frame, f"CAMARA {cam_id + 1}", (200, 200), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(frame, "SIN SE√ëAL", (250, 250), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return frame
    
    def get_metrics(self, cam_id):
        """Obtiene m√©tricas de una c√°mara"""
        vehicles = self.vehicle_counts.get(cam_id, 0)
        classes = self.vehicle_classes.get(cam_id, {})
        
        return vehicles, classes
    
    def stop(self):
        """Detiene el procesamiento"""
        self.processing = False
        for cap in self.video_caps.values():
            cap.release()
        print("üõë Procesamiento detenido")

# Instancia global
video_processor = VideoProcessor()

def generate_frames(camera_id):
    """Generador de frames para streaming"""
    print(f"üì° Iniciando stream para c√°mara {camera_id}")
    
    while True:
        try:
            frame_bytes = video_processor.get_frame(camera_id)
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            time.sleep(0.033)  # ~30 FPS
        except Exception as e:
            print(f"‚ùå Error en stream c√°mara {camera_id}: {e}")
            time.sleep(1)